{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "______________________________________\n",
    "# <center>**Trabajo Practico N¬∫2 para la Materia *Organizaci√≥n de Datos***</center>\n",
    "\n",
    "*Integrantes*:\n",
    "- 103963\tCarolina Di Matteo\tcdimatteo@fi.uba.ar\n",
    "- 101231\tPablo Salvador Dimartino\tpdimartino@fi.uba.ar\n",
    "- 100113\tJuan Sebastian Burgos\tjsburgos@fi.uba.ar\n",
    "- 104415\tValentina Laura Correa\tvcorrea@fi.uba.ar\n",
    "\n",
    "*Grupo*: 14\n",
    "\n",
    "*Repositorio*: [github](https://github.com/valencorrea/7506R-2C2022-GRUPO14)\n",
    "\n",
    "*Curso*: Rodriguez\n",
    "\n",
    "*Cuatrimestre*: 2c2022\n",
    "\n",
    "Datos provistos por [properati](https://www.properati.com.ar).\n",
    "______________________________________\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ALhQpMoS2Do2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introducci√≥n"
   ],
   "metadata": {
    "id": "jrObdaVTw13E"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "El presente trabajo pr√°ctico es una continuaci√≥n del ‚ÄòTP1: Propiedades en Venta‚Äô. \n",
    "\n",
    "En la entrega anterior se propuso aplicar t√©cnicas de an√°lisis exploratorio, preprocesamiento de datos, agrupamiento, clasificaci√≥n y regresi√≥n. Siguiendo esta l√≠nea, y con el objetivo de continuar resolviendo problemas reales de ciencia de datos, en esta segunda parte se implementar√°n nuevos modelos predictivos a partir de los anteriormente mencionados. \n",
    "\n",
    "En esta oportunidad se buscar√° demostrar los conocimientos adquiridos sobre procesamiento del lenguaje natural, redes neuronales y ensamble de modelos. Para esto se utilizar√°n tanto datasets provistos por la materia, tomados de la p√°gina de la empresa Properati, como los generados por el grupo en el trabajo anterior."
   ],
   "metadata": {
    "id": "8Tot765gvLP2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 0. Setup"
   ],
   "metadata": {
    "id": "civIgEQKvQ6A"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importaci√≥n de bibliotecas"
   ],
   "metadata": {
    "id": "vrqonJJjvVay"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: visualkeras in /home/juanse/.local/lib/python3.10/site-packages (0.0.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from visualkeras) (9.0.1)\r\n",
      "Requirement already satisfied: aggdraw>=1.3.11 in /home/juanse/.local/lib/python3.10/site-packages (from visualkeras) (1.3.15)\r\n",
      "Requirement already satisfied: numpy>=1.18.1 in /home/juanse/.local/lib/python3.10/site-packages (from visualkeras) (1.23.3)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install visualkeras"
   ],
   "metadata": {
    "id": "h6RrCiyq2Do7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3e7b3e93-b112-4351-a933-5d45f291d371"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install scikeras[tensorflow]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pip install scikeras[tensorflow-cpu]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pip install unidecode"
   ],
   "metadata": {
    "id": "vdZzPMc93I-C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "045bdfc2-9805-43c2-c41d-1cd20aa7efce"
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: unidecode in /usr/local/lib/python3.10/dist-packages (1.3.6)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pip install types-all"
   ],
   "metadata": {
    "id": "7SrZ6Pvh8b_K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2aff2586-af7e-4665-9009-c3ba548ce286"
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: types-all in /home/juanse/.local/lib/python3.10/site-packages (1.0.0)\r\n",
      "Requirement already satisfied: types-click-spinner in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.13.1)\r\n",
      "Requirement already satisfied: types-six in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.16.21.4)\r\n",
      "Requirement already satisfied: types-tzlocal in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (4.2.2.2)\r\n",
      "Requirement already satisfied: types-docutils in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.19.1.1)\r\n",
      "Requirement already satisfied: types-dateparser in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.4.4)\r\n",
      "Requirement already satisfied: types-python-gflags in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.1.7.1)\r\n",
      "Requirement already satisfied: types-pyvmomi in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (8.0.0.0)\r\n",
      "Requirement already satisfied: types-PyMySQL in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.0.19.1)\r\n",
      "Requirement already satisfied: types-maxminddb in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.5.0)\r\n",
      "Requirement already satisfied: types-characteristic in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (14.3.7)\r\n",
      "Requirement already satisfied: types-cachetools in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.2.1)\r\n",
      "Requirement already satisfied: types-pysftp in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.2.17)\r\n",
      "Requirement already satisfied: types-DateTimeRange in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.2.8)\r\n",
      "Requirement already satisfied: types-ujson in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.6.0.0)\r\n",
      "Requirement already satisfied: types-MarkupSafe in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.10)\r\n",
      "Requirement already satisfied: types-Werkzeug in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.0.9)\r\n",
      "Requirement already satisfied: types-croniter in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.3.2.1)\r\n",
      "Requirement already satisfied: types-pycurl in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (7.45.2.0)\r\n",
      "Requirement already satisfied: types-pyaudio in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.2.16.4)\r\n",
      "Requirement already satisfied: types-aiofiles in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (22.1.0.4)\r\n",
      "Requirement already satisfied: types-toml in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.10.8.1)\r\n",
      "Requirement already satisfied: types-typed-ast in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.5.8.3)\r\n",
      "Requirement already satisfied: types-backports in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.3)\r\n",
      "Requirement already satisfied: types-certifi in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2021.10.8.3)\r\n",
      "Requirement already satisfied: types-python-dateutil in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.8.19.5)\r\n",
      "Requirement already satisfied: types-colorama in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.4.15.4)\r\n",
      "Requirement already satisfied: types-Pillow in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (9.3.0.4)\r\n",
      "Requirement already satisfied: types-atomicwrites in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.4.5.1)\r\n",
      "Requirement already satisfied: types-Markdown in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.4.2.1)\r\n",
      "Requirement already satisfied: types-enum34 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.8)\r\n",
      "Requirement already satisfied: types-orjson in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.6.2)\r\n",
      "Requirement already satisfied: types-contextvars in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.4.7)\r\n",
      "Requirement already satisfied: types-Jinja2 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.11.9)\r\n",
      "Requirement already satisfied: types-pyfarmhash in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.3.1)\r\n",
      "Requirement already satisfied: types-PyYAML in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (6.0.12.2)\r\n",
      "Requirement already satisfied: types-freezegun in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.10)\r\n",
      "Requirement already satisfied: types-click in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (7.1.8)\r\n",
      "Requirement already satisfied: types-JACK-Client in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.5.10.3)\r\n",
      "Requirement already satisfied: types-pymssql in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.1.0)\r\n",
      "Requirement already satisfied: types-dataclasses in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.6.6)\r\n",
      "Requirement already satisfied: types-fb303 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.0.0)\r\n",
      "Requirement already satisfied: types-pkg-resources in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.3)\r\n",
      "Requirement already satisfied: types-futures in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.3.8)\r\n",
      "Requirement already satisfied: types-redis in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (4.3.21.6)\r\n",
      "Requirement already satisfied: types-decorator in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.1.8.1)\r\n",
      "Requirement already satisfied: types-mypy-extensions in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.4.24)\r\n",
      "Requirement already satisfied: types-Flask in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.6)\r\n",
      "Requirement already satisfied: types-protobuf in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (4.21.0.2)\r\n",
      "Requirement already satisfied: types-retry in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.9.9)\r\n",
      "Requirement already satisfied: types-scribe in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.0.0)\r\n",
      "Requirement already satisfied: types-PyJWT in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.7.1)\r\n",
      "Requirement already satisfied: types-frozendict in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.0.9)\r\n",
      "Requirement already satisfied: types-Routes in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.5.0)\r\n",
      "Requirement already satisfied: types-nmap in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.6)\r\n",
      "Requirement already satisfied: types-filelock in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.2.7)\r\n",
      "Requirement already satisfied: types-requests in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.28.11.6)\r\n",
      "Requirement already satisfied: types-boto in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.49.18.3)\r\n",
      "Requirement already satisfied: types-kazoo in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.3)\r\n",
      "Requirement already satisfied: types-termcolor in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.6)\r\n",
      "Requirement already satisfied: types-pytz in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2022.7.0.0)\r\n",
      "Requirement already satisfied: types-Deprecated in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.2.9)\r\n",
      "Requirement already satisfied: types-cryptography in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.3.23.2)\r\n",
      "Requirement already satisfied: types-waitress in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.1.4.3)\r\n",
      "Requirement already satisfied: types-docopt in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.6.11)\r\n",
      "Requirement already satisfied: types-emoji in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.1.0.1)\r\n",
      "Requirement already satisfied: types-backports-abc in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.5.2)\r\n",
      "Requirement already satisfied: types-singledispatch in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.7.5.1)\r\n",
      "Requirement already satisfied: types-tornado in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.1.1)\r\n",
      "Requirement already satisfied: types-ipaddress in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.0.8)\r\n",
      "Requirement already satisfied: types-mock in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (4.0.15.2)\r\n",
      "Requirement already satisfied: types-pathlib2 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.3.0)\r\n",
      "Requirement already satisfied: types-python-slugify in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (7.0.0.1)\r\n",
      "Requirement already satisfied: types-paramiko in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.12.0.1)\r\n",
      "Requirement already satisfied: types-simplejson in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.18.0.0)\r\n",
      "Requirement already satisfied: types-first in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (2.0.5)\r\n",
      "Requirement already satisfied: types-chardet in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.0.4.1)\r\n",
      "Requirement already satisfied: types-annoy in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.17.8.1)\r\n",
      "Requirement already satisfied: types-polib in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.12.1)\r\n",
      "Requirement already satisfied: types-itsdangerous in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.6)\r\n",
      "Requirement already satisfied: types-openssl-python in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.1.3)\r\n",
      "Requirement already satisfied: types-xxhash in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.0.5.1)\r\n",
      "Requirement already satisfied: types-geoip2 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (3.0.0)\r\n",
      "Requirement already satisfied: types-pyRFC3339 in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (1.1.1.1)\r\n",
      "Requirement already satisfied: types-tabulate in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (0.9.0.0)\r\n",
      "Requirement already satisfied: types-bleach in /home/juanse/.local/lib/python3.10/site-packages (from types-all) (5.0.3.1)\r\n",
      "Requirement already satisfied: types-urllib3<1.27 in /home/juanse/.local/lib/python3.10/site-packages (from types-requests->types-all) (1.26.25.4)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 00:25:25.416998: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Importaci√≥n de librer√≠as\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import re\n",
    "from joblib import load, dump\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from keras.metrics import MeanSquaredError\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, precision_score, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Configuraci√≥n de Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "#Ejecuci√≥n con Drive\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    IN_COLAB = True\n",
    "else:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB :\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    properati = pd.read_csv('/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/1d_df_reducido.csv')\n",
    "    properati_descrip = pd.read_csv('/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP1/properati_argentina_2021_decrip.csv')\n",
    "    stop_words = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/stopwords.txt'\n",
    "else:\n",
    "    # properati = pd.read_csv('./1d_df_reducido.csv')\n",
    "    df_train = pd.read_csv('./DATASETS/df_train_tp1.csv')\n",
    "    df_test = pd.read_csv('./DATASETS/df_test_tp1.csv')\n",
    "    properati_descrip = pd.read_csv('properati_argentina_2021_decrip.csv')\n",
    "    stop_words = 'stopwords'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funciones auxiliares"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def metricas_clasificacion(y_test, y_pred):\n",
    "    print(f'Accuracy: {round(accuracy_score(y_test, y_pred),2)}')\n",
    "    print(f'Precision: {round(precision_score(y_test, y_pred, average=\"macro\"),2)}')\n",
    "    print(f'Recall: {round(recall_score(y_test, y_pred, average=\"macro\"),2)}')\n",
    "    print(f'F1 Score: {round(f1_score(y_test, y_pred, average=\"macro\"),2)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediccion_y_metricas_regresion(regressor, x_test, y_test):\n",
    "\n",
    "  y_pred = regressor.predict(x_test)\n",
    "\n",
    "  print(f\"Se obtuvo un Score de {round(regressor.score(x_test, y_test)*100,3)}%\")\n",
    "\n",
    "  mse = metrics.mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = y_pred,\n",
    "        squared = True\n",
    "       )\n",
    "\n",
    "  print(f\"El error seg√∫n la m√©trica 'Mean Square Error' de test es: {mse}\")\n",
    "\n",
    "  rmse = metrics.mean_squared_error(\n",
    "        y_true  = y_test,\n",
    "        y_pred  = y_pred,\n",
    "        squared = False\n",
    "       )\n",
    "\n",
    "  print(f\"El error seg√∫n la m√©trica 'Root Mean Square Error' de test es: {rmse}\")\n",
    "\n",
    "  return"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def format_aspects(line, word):\n",
    "    format = r\"\\W*([\\w]+)\"\n",
    "    n = 2\n",
    "    x = re.search(r'{}\\W*{}{}'.format(format*n, word, format*n), line)\n",
    "    if x is not None:\n",
    "        return x.group()\n",
    "    else:\n",
    "        return \"\""
   ],
   "metadata": {
    "id": "CCKsO-A5w7TQ",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_b_m_a(x):\n",
    "    mx = max(x[0], x[1], x[2])\n",
    "    if mx == x[0]:\n",
    "        return 'bajo'\n",
    "    elif mx == x[1]:\n",
    "        return 'medio'\n",
    "    elif mx == x[2]:\n",
    "        return 'alto'"
   ],
   "metadata": {
    "id": "3suAr0ciwY91",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def estandarizar(df, columns):\n",
    "  sscaler = StandardScaler()\n",
    "\n",
    "  for col in columns:\n",
    "    df[col] = sscaler.fit_transform(pd.DataFrame(df[col]))"
   ],
   "metadata": {
    "id": "0LF1eyB9l4nt",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def limpiar_values_de_aspects(df, aspects, values):\n",
    "    i = 0\n",
    "    for aspect in aspects:\n",
    "        for word in values[i]:\n",
    "            df[aspect] = df[aspect].apply(lambda line: word if word in line else line)\n",
    "        df[aspect] = df[aspect].apply(lambda line: line if len(line.split())<2 else '')\n",
    "        i = i+1"
   ],
   "metadata": {
    "id": "AAEy2PV92DpO",
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def evaluate_model(model, x, y, splits, n):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=splits, n_repeats=n, random_state=1)\n",
    "    scores = cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv, verbose=1, n_jobs=3, error_score='raise')\n",
    "    return scores"
   ],
   "metadata": {
    "id": "tDt5-bPcEn_m",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_results(model_scores, name):\n",
    "    \n",
    "    model_names = list(model_scores.keys())\n",
    "    results = [model_scores[model] for model in model_names]\n",
    "    fig = go.Figure()\n",
    "    for model, result in zip(model_names, results):\n",
    "        fig.add_trace(go.Box(\n",
    "            y=result,\n",
    "            name=model,\n",
    "            boxpoints='all',\n",
    "            jitter=0.5,\n",
    "            whiskerwidth=0.2,\n",
    "            marker_size=2,\n",
    "            line_width=1)\n",
    "        )\n",
    "    \n",
    "    fig.update_layout(\n",
    "    title='Performance of Different Models Using 5-Fold Cross-Validation',\n",
    "    paper_bgcolor='rgb(243, 243, 243)',\n",
    "    plot_bgcolor='rgb(243, 243, 243)',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='Error Cuadr√°tico Medio',\n",
    "    showlegend=False)\n",
    "    fig.show()"
   ],
   "metadata": {
    "id": "NImxsouY4HaJ",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparaci√≥n de datasets"
   ],
   "metadata": {
    "id": "yG33nESmvkqN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_x = df_train.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
    "df_train_y_regresion = df_train[\"property_price\"]\n",
    "df_train_y_clasificacion = df_train[\"tipo_precio_3\"]\n",
    "\n",
    "df_test_x = df_test.drop([\"property_price\", \"tipo_precio_3\"], axis=\"columns\")\n",
    "df_test_y_regresion = df_test[\"property_price\"]\n",
    "df_test_y_clasificacion = df_test[\"tipo_precio_3\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Procesamiento del Lenguaje Natural"
   ],
   "metadata": {
    "collapsed": false,
    "id": "DajLENWv2DpA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.a Ampliaci√≥n del dataset\n",
    "___"
   ],
   "metadata": {
    "id": "mmjJ3qskuJyJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hacemos un merge del dataset original y el de descripciones, y qued√©monos √∫nicamente con las columnas `id` y `property_description`:"
   ],
   "metadata": {
    "id": "904YC-oLyddb"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df_descrip = pd.merge(df_train_x, properati_descrip, on=\"id\")\n",
    "df_descrip = df_descrip[[\"id\", \"property_description\"]]\n",
    "\n",
    "df_test_descrip = pd.merge(df_test_x, properati_descrip, on=\"id\")\n",
    "df_test_descrip = df_test_descrip[[\"id\", \"property_description\"]]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "vRbU2jpk2Do_",
    "outputId": "44fcabfb-0e8b-496a-881f-0de5fbc8f3e6"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "                             id  \\\n0      ahcEMvB66wjPz0SYWZQDBw==   \n1      M0g0l0s6S13X+cZlGkUo8g==   \n2      V/KMMLRRx/Nn+g3m5lrW7A==   \n3      odR0QjYc3xtaYfqNJvbOSQ==   \n4      RqOcPIKYYZDG+CFMq2c1RA==   \n...                         ...   \n18600  g2fBcuyxiq3V0GdPATLFDw==   \n18601  2jfcV70r5M8iASKFbpFEqA==   \n18602  H4X7bNq04pK7U6fCcbxYNg==   \n18603  QWBP5Zp0TBUlFrzP9GO9bA==   \n18604  pKo6hHHPBZJydrHIn5S5Tg==   \n\n                                    property_description  \n0      Corredor Responsable: Juan Carlos Treco - CUCI...  \n1      Corredor Responsable: Micaela Perez / Lucas Fe...  \n2      Corredor Responsable: Gustavo Guastello - C.U....  \n3      PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...  \n4      EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...  \n...                                                  ...  \n18600  Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...  \n18601  Departamento a estrenar monoambiente, luminoso...  \n18602  Corredor Responsable: Daniel Acosta - CUCICBA ...  \n18603  El departamento se ubica en la PB y contiene:<...  \n18604  Departamento tipo PH en el hermoso edificio hi...  \n\n[18605 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>property_description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ahcEMvB66wjPz0SYWZQDBw==</td>\n      <td>Corredor Responsable: Juan Carlos Treco - CUCI...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>M0g0l0s6S13X+cZlGkUo8g==</td>\n      <td>Corredor Responsable: Micaela Perez / Lucas Fe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V/KMMLRRx/Nn+g3m5lrW7A==</td>\n      <td>Corredor Responsable: Gustavo Guastello - C.U....</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>odR0QjYc3xtaYfqNJvbOSQ==</td>\n      <td>PH A ESTRENAR SANCHEZ DE LORIA AL 1500 Y CONST...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RqOcPIKYYZDG+CFMq2c1RA==</td>\n      <td>EXCELENTE SEMIPISO 3 AMB C/BALCON LUMINOSO EN ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18600</th>\n      <td>g2fBcuyxiq3V0GdPATLFDw==</td>\n      <td>Venta DEPARTAMENTO 2 Ambientes Villa Ortuzar. ...</td>\n    </tr>\n    <tr>\n      <th>18601</th>\n      <td>2jfcV70r5M8iASKFbpFEqA==</td>\n      <td>Departamento a estrenar monoambiente, luminoso...</td>\n    </tr>\n    <tr>\n      <th>18602</th>\n      <td>H4X7bNq04pK7U6fCcbxYNg==</td>\n      <td>Corredor Responsable: Daniel Acosta - CUCICBA ...</td>\n    </tr>\n    <tr>\n      <th>18603</th>\n      <td>QWBP5Zp0TBUlFrzP9GO9bA==</td>\n      <td>El departamento se ubica en la PB y contiene:&lt;...</td>\n    </tr>\n    <tr>\n      <th>18604</th>\n      <td>pKo6hHHPBZJydrHIn5S5Tg==</td>\n      <td>Departamento tipo PH en el hermoso edificio hi...</td>\n    </tr>\n  </tbody>\n</table>\n<p>18605 rows √ó 2 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_descrip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Busquemos aspectos de una propiedad utilizando la columna `property_description`."
   ],
   "metadata": {
    "id": "uCEL8YyUxYaa"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cu√°ntos registros nulos existen:"
   ],
   "metadata": {
    "id": "tAEE-G_QzCXj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 0 datos nulos.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hay {df_descrip['property_description'].isna().sum()} datos nulos.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydHTArN62DpA",
    "outputId": "532aec7a-b0bc-4f97-d56d-80ee53135a25"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cu√°les son las 100 palabras m√°s comunes en el campo de descripci√≥n de propiedades:"
   ],
   "metadata": {
    "id": "t4hiRECrz3Wa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "[('de', 857976),\n ('y', 507778),\n ('con', 401867),\n ('la', 290195),\n ('en', 278176),\n ('a', 243751),\n ('el', 169952),\n ('del', 153279),\n ('que', 140055),\n ('por', 133635),\n ('al', 125215),\n ('-', 113875),\n ('un', 103716),\n ('las', 90713),\n ('los', 88435),\n ('para', 88190),\n ('se', 63109),\n ('DE', 56457),\n ('son', 56420),\n ('2', 52790),\n ('es', 50384),\n ('una', 48927),\n ('3', 41258),\n ('cocina', 38889),\n ('ambientes', 38848),\n ('valor', 38420),\n ('esta', 38292),\n ('muy', 36893),\n ('x', 36800),\n ('Av.', 36630),\n ('comedor', 35535),\n ('ba√±o', 35476),\n ('Y', 34141),\n ('CON', 33915),\n ('no', 33912),\n ('piso', 33348),\n ('o', 33050),\n ('/', 32253),\n ('tu', 32101),\n ('A', 32063),\n ('hasta', 30269),\n ('balc√≥n', 29805),\n ('inmueble', 28725),\n ('casa', 28655),\n ('No', 28635),\n ('propiedad.', 28070),\n ('30%', 27684),\n ('departamento', 27670),\n ('EN', 27267),\n ('cuadras', 27069),\n ('Corredor', 26991),\n ('pr√©stamo', 26920),\n ('cuota', 26780),\n ('medidas', 26422),\n ('Responsable:', 25970),\n ('living', 25952),\n ('4', 25848),\n ('Lendar', 25571),\n ('quer√©s!', 25421),\n ('pod√©s.', 25362),\n ('Acced√©', 25354),\n ('Simul√°', 25349),\n ('#', 25248),\n ('ID', 25231),\n ('MLS', 25227),\n ('CUCICBA', 24648),\n ('El', 24541),\n ('edificio', 24305),\n ('dos', 24304),\n ('cuenta', 24241),\n ('personas', 23936),\n ('completo', 23797),\n ('propiedad', 23309),\n ('salida', 23058),\n ('parte', 22277),\n (',', 22138),\n ('pisos', 21621),\n ('encuentra', 21617),\n ('frente', 21612),\n ('Las', 21073),\n ('1', 20964),\n ('amplio', 20885),\n ('Compr√°', 20793),\n ('\\\\n\\\\n', 20732),\n ('vista', 19912),\n ('presente', 19511),\n ('dormitorio', 19499),\n ('Ley', 19317),\n ('gran', 19096),\n ('La', 18859),\n ('placard', 18483),\n ('espacio', 18475),\n ('metros', 18400),\n ('m2', 17976),\n ('Los', 17521),\n ('<br>', 17369),\n ('accesible', 17076),\n ('su', 16596),\n ('dormitorios', 16161),\n ('sobre', 16145)]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpAlq6jJ2DpC",
    "outputId": "ba6d7ea0-e0b6-4446-d3e2-550d723373d2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos observar que podr√≠amos optimizar el texto mediante algunas t√©cnicas de reducci√≥n y/o transformaci√≥n. Entre otras:"
   ],
   "metadata": {
    "id": "iwnQ6tgt0MRV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos la etiqueta `<br>` de html:"
   ],
   "metadata": {
    "id": "qK78Ucya0Ugr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.replace(\"<br>\", \" \"))"
   ],
   "metadata": {
    "id": "_o_B51Zk0hGz"
   },
   "execution_count": 60,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformemos todas las palabras a min√∫sculas, de modo que el contador no realice distinciones:"
   ],
   "metadata": {
    "id": "pyNp4Y520yHS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: line.lower())\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: line.lower())\n"
   ],
   "metadata": {
    "id": "VWBmcgfI04Ge"
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quitemos los t√≠ldes de las letras:"
   ],
   "metadata": {
    "id": "WpSPMtks1bZz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: unidecode.unidecode(line))"
   ],
   "metadata": {
    "id": "KWHrTmAG1dGn"
   },
   "execution_count": 62,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [62], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m line: unidecode\u001B[38;5;241m.\u001B[39munidecode(line))\n\u001B[1;32m      2\u001B[0m df_test_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df_test_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m line: unidecode\u001B[38;5;241m.\u001B[39munidecode(line))\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:4774\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4664\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4665\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4666\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4669\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4670\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4671\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4672\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4673\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4772\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4773\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4774\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1100\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:1151\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1150\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1151\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1152\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1153\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1154\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1159\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2919\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn [62], line 1\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(line)\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m line: \u001B[43munidecode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munidecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mline\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      2\u001B[0m df_test_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m df_test_descrip[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproperty_description\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m line: unidecode\u001B[38;5;241m.\u001B[39munidecode(line))\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/unidecode/__init__.py:66\u001B[0m, in \u001B[0;36munidecode_expect_ascii\u001B[0;34m(string, errors, replace_str)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m string\n\u001B[0;32m---> 66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_unidecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstring\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace_str\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/unidecode/__init__.py:121\u001B[0m, in \u001B[0;36m_unidecode\u001B[0;34m(string, errors, replace_str)\u001B[0m\n\u001B[1;32m    118\u001B[0m retval \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, char \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(string):\n\u001B[0;32m--> 121\u001B[0m     repl \u001B[38;5;241m=\u001B[39m \u001B[43m_get_repl_str\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m repl \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/unidecode/__init__.py:86\u001B[0m, in \u001B[0;36m_get_repl_str\u001B[0;34m(char)\u001B[0m\n\u001B[1;32m     82\u001B[0m codepoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mord\u001B[39m(char)\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m codepoint \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0x80\u001B[39m:\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;66;03m# Already ASCII\u001B[39;00m\n\u001B[0;32m---> 86\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m codepoint \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0xeffff\u001B[39m:\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;66;03m# No data on characters in Private Use Area and above.\u001B[39;00m\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos los s√≠mbolos:"
   ],
   "metadata": {
    "id": "tpUndCZy1j2X"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(r'[^\\w]', ' ', line))"
   ],
   "metadata": {
    "id": "sWcF2SIJ1lfG"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eliminemos los espacios m√∫ltiples entre palabras:"
   ],
   "metadata": {
    "id": "bdqDlvqN1rL1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(lambda line: re.sub(\"\\s\\s+\" , \" \", line))"
   ],
   "metadata": {
    "id": "uQvajcwC2DpE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizando el contenido del archivo `stop_words.txt`, eliminemos palabras sin significado del datset y colocamos los cambios en uno nuevo:"
   ],
   "metadata": {
    "id": "BzcWZSJY4GPs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(stop_words) as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "f = lambda x: ' '.join([item for item in x.split() if item not in lines])\n",
    "\n",
    "df_descrip[\"property_description\"] = df_descrip[\"property_description\"].apply(f)\n",
    "df_test_descrip[\"property_description\"] = df_test_descrip[\"property_description\"].apply(f)"
   ],
   "metadata": {
    "id": "FrOeCCBY2DpF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego de estas transformaciones, veamos cu√°les son las palabras m√°s utilizadas:"
   ],
   "metadata": {
    "id": "JYXs-85EVQwx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"property_description\"]).split()).most_common(100)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNYcv0DM2DpG",
    "outputId": "eed3ff96-3911-4d2a-a042-969e76b82e01"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seleccionemos los aspectos que nos parecen relevantes, para luego buscar sus posibles valores.\n",
    "\n",
    "Para esto, elegimos: `cocina`, `pisos`, `calefaccion`, `expensas`, `lavadero`, `balcon`, `cochera` y `aire` y limpiamos cualquier tipo de formato restante en el dataset:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ai_Odw_x2DpG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "aspectos = ['cocina', 'pisos', 'calefaccion', 'expensas', 'lavadero', 'balcon', 'cochera', 'aire']"
   ],
   "metadata": {
    "id": "BkHpD1gtB7e_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for word in aspectos:\n",
    "    df_descrip[word] = df_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))\n",
    "    df_test_descrip[word] = df_test_descrip[\"property_description\"].apply(lambda line: format_aspects(line, word))"
   ],
   "metadata": {
    "id": "AnaswxtR2DpH"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos cu√°les son las 15 palabras m√°s comunes para cada uno de los aspectos elegidos:"
   ],
   "metadata": {
    "id": "EDsk7Bjgx116"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cant_val_aspectos = 15"
   ],
   "metadata": {
    "id": "eYdLqsvGyNcj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `cocina`\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "wWJKdB85y1l0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"cocina\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "l-7v9FP82DpH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6bea24da-1ae1-4df4-eb9a-5fddb082398b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `cocina`, los valores podr√≠an ser: \n",
    "- integrada\n",
    "- lavadero\n",
    "- completa"
   ],
   "metadata": {
    "collapsed": false,
    "id": "6ACLlV0F2DpI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `pisos`"
   ],
   "metadata": {
    "id": "1XQ4TVyUzSqc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"pisos\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "UQQMsrnL2DpI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a261ec0d-9cd6-4277-98b0-7b18d0b28211"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `pisos`, los valores podr√≠an ser: \n",
    "- porcelanato\n",
    "- parquet\n",
    "- madera"
   ],
   "metadata": {
    "collapsed": false,
    "id": "l39ZahiN2DpJ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `calefaccion`"
   ],
   "metadata": {
    "id": "a4pG3YbW1wnt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"calefaccion\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "RPZApHfA2DpJ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "67f4d899-74cf-4d93-ea99-c89946b6f262"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `calefaccion`, los valores podr√≠an ser: \n",
    "- radiadores\n",
    "- radiante\n",
    "- central\n",
    "- individual"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Mt-7dfsl2DpK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `expensas`"
   ],
   "metadata": {
    "id": "XfzRZc861ysa"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"expensas\"]).split()).most_common(cant_val_aspectos*2)"
   ],
   "metadata": {
    "id": "iRKPdGhA2DpK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e89ec902-f5d3-45e5-df24-45d796fd889b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `expensas`, los valores podr√≠an ser: \n",
    "- servicios\n",
    "- impuestos \n",
    "- bajas"
   ],
   "metadata": {
    "collapsed": false,
    "id": "C7EiojY82DpK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `lavadero`"
   ],
   "metadata": {
    "id": "ZVVvuLxu11U0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"lavadero\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "sAzBKC5c2DpK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c811e281-914c-4804-fe87-064ada17a12d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `lavadero`, los valores podr√≠an ser: \n",
    "- independiente\n",
    "- cocina\n",
    "- comedor"
   ],
   "metadata": {
    "collapsed": false,
    "id": "i8zxU-Co2DpL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `balcon`"
   ],
   "metadata": {
    "id": "0opxhwgx122i"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"balcon\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "geCmhGct2DpL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7f9103b9-03aa-4035-dd78-c3a1c435e833"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `balcon`, los valores podr√≠an ser: \n",
    "- frente\n",
    "- amplio \n",
    "- terraza \n",
    "- salida \n",
    "- corrido\n",
    "- luminoso"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GUiM00PQ2DpL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `cochera`"
   ],
   "metadata": {
    "id": "W05qxE7f138s"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"cochera\"]).split()).most_common(cant_val_aspectos*2)"
   ],
   "metadata": {
    "id": "vF7x7sFV2DpL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa1e9494-2db9-48dd-8101-5987d80ccb55"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `cochera`, los valores podr√≠an ser: \n",
    "- fija\n",
    "- cubierta"
   ],
   "metadata": {
    "collapsed": false,
    "id": "_sGYjhjF2DpM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Aspecto `aire`"
   ],
   "metadata": {
    "id": "ehAh9leY2Lfu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Counter(\" \".join(df_descrip[\"aire\"]).split()).most_common(cant_val_aspectos)"
   ],
   "metadata": {
    "id": "eQlqeMRa2DpM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fa0a82b5-9f5b-4ab4-80b7-f0090e746727"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para `aire`, posibles valores son: \n",
    "- split \n",
    "- central \n",
    "- acondicionado"
   ],
   "metadata": {
    "collapsed": false,
    "id": "9hWHT90P2DpM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Consolidaci√≥n de valores"
   ],
   "metadata": {
    "id": "fF4R61si2RJI"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A continuaci√≥n creamos la variable `values`, que contiene los posibles valores para cada uno de los aspectos elegidos:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZTu9pPYV2DpN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values_cocina = ['integrada' , 'lavadero' , 'completa']\n",
    "values_pisos = ['porcelanato' , 'parquet' , 'madera']\n",
    "values_calefaccion = ['radiadores' , 'radiante' , 'central' , 'individual']\n",
    "values_expensas = ['serviocios' , 'impuestos' , 'bajas']\n",
    "values_lavadero = ['independiente' , 'cocina' , 'comedor']\n",
    "values_balcon = ['frente' , 'amplio' , 'terraza' , 'salida' , 'corrido' , 'luminoso']\n",
    "values_cochera = ['fija' , 'cubierta']\n",
    "values_aire = ['split' , 'central' , 'acondicionado']"
   ],
   "metadata": {
    "id": "8woiCcO32DpN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "values = [values_cocina, values_pisos, values_calefaccion, values_expensas, values_lavadero, values_balcon, values_cochera, values_aire]"
   ],
   "metadata": {
    "id": "CFU_0j0EGUE5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "En primer lugar, creamos un dataset auxiliar que tenga los IDs y las columnas de los aspectos:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "B9JpAzOi2DpN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aux_df = df_descrip.copy()\n",
    "aux_df_test = df_test_descrip.copy()\n",
    "\n",
    "aux_df.drop('property_description', inplace=True, axis=1)\n",
    "aux_df_test.drop('property_description', inplace=True, axis=1)"
   ],
   "metadata": {
    "id": "Z617kPUE2DpN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego creamos una funci√≥n a la que -pas√°ndole un dataset, los aspectos y el listado de valores posibles- reemplace el contenido de las columnas por los valores correspondientes."
   ],
   "metadata": {
    "collapsed": false,
    "id": "qpHzefm72DpO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modificamos las columnas de los aspectos, para que s√≥lo queden los valores correspondientes:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "8A7lmncH2DpO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "limpiar_values_de_aspects(aux_df, aspectos, values)\n",
    "limpiar_values_de_aspects(aux_df_test, aspectos, values)\n",
    "aux_df.head(20)"
   ],
   "metadata": {
    "id": "WXhzGxCl2DpO",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "outputId": "3355d0c0-87e8-4707-b349-e4d9b468bfa9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Por √∫ltimo hacemos el merge con el dataset original, teniendo en cuenta los IDs:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Ia2LxOLq2DpP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df_train_x.copy()\n",
    "df = pd.merge(df,aux_df, on=\"id\")\n",
    "df.drop(\"id\", inplace=True, axis=\"columns\")\n",
    "\n",
    "df_test = df_test_x.copy()\n",
    "df_test = pd.merge(df_test,aux_df_test, on=\"id\")\n",
    "df_test.drop(\"id\", inplace=True, axis=\"columns\")\n",
    "\n",
    "df.head(20)"
   ],
   "metadata": {
    "id": "I2x-X60t2DpP",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "outputId": "9aa74e5a-0b67-4010-a31b-a2f67689e136"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exportaci√≥n de Datos"
   ],
   "metadata": {
    "id": "rN3FutIEHrf2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exportamos los datasets generados:"
   ],
   "metadata": {
    "id": "xd-CoUsZHtL9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/DATASETS/1a_df_descrip.csv'\n",
    "else:\n",
    "  path = 'DATASETS/1a_df_descrip.csv'\n",
    "\n",
    "df_descrip.to_csv(path)"
   ],
   "metadata": {
    "id": "qr1jlB8QH16Z"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/DATASETS/1a_df_ampliado.csv'\n",
    "else:\n",
    "  path = 'DATASETS/1a_df_ampliado.csv'\n",
    "\n",
    "df.to_csv(path)"
   ],
   "metadata": {
    "id": "QTsLoqr-IHOX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.b Modelos\n",
    "___"
   ],
   "metadata": {
    "collapsed": false,
    "id": "fI1Fi95S2DpP"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sin optimizaci√≥n de hiperpar√°metros"
   ],
   "metadata": {
    "id": "ldOrNGnEaE5H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenemos un modelo de XGBoost con los mismos hiperpar√°metros utilizados en el TP1."
   ],
   "metadata": {
    "id": "a2X0YkeUUL1X"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Realizamos One Hot Encoding para las nuevas variables cualitativas:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "WqUMr9_r2DpQ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
    "df_test_dummies = pd.get_dummies(df_test, columns=['cocina', 'pisos', 'lavadero', 'calefaccion', 'expensas', 'balcon', 'cochera', 'aire'], drop_first=True)\n",
    "df_dummies.head(5)"
   ],
   "metadata": {
    "id": "5e0r2Yj-2DpQ",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "outputId": "9345f93a-6a15-48ed-ebd9-8004cb87637f"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dummies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos el modelo:"
   ],
   "metadata": {
    "id": "I6cp1CI3ZKLx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_test_dummies"
   ],
   "metadata": {
    "id": "kQ5AadFSfxhE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "044f7dba-5555-4d62-b84e-494ca9febd99"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "XGB_Regressor = XGBRegressor(min_child_weight = 5, max_depth = 6, learning_rate = 0.3, gamma = 0.1, colsample_bytree = 0.3)\n",
    "XGB_Regressor.fit(df_dummies, df_train_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hagamos las predicciones y veamos c√≥mo resultaron las m√©tricas del modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediccion_y_metricas_regresion(XGB_Regressor,df_test_dummies, df_test_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importancia de features\n",
    "Graficamos los 15 features m√°s importantes para el modelo con los hiperpar√°metros del TP1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_idx = XGB_Regressor.feature_importances_.argsort()\n",
    "sorted_idx = sorted_idx[-15:]\n",
    "plt.barh(df_test_dummies.columns[sorted_idx], XGB_Regressor.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos observar que el feature m√°s importante es la ubicaci√≥n en Puerto Madero, seguido de cantidad de habitaciones y ubicaci√≥n en Palermo Chico."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Con optimizaci√≥n de hiperpar√°metros"
   ],
   "metadata": {
    "id": "CkJCoGXnaN1y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos c√≥mo se comporta el score con la optimizaci√≥n de hiperpar√°metros:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "Su2wKojB2DpR"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "params_grid = {'learning_rate': [0.20, 0.25, 0.30],\n",
    "               'max_depth': [4, 5, 6, 8, 10],\n",
    "               'min_child_weight': [1, 3, 5, 7, 9],\n",
    "               'gamma': [0.1, 0.2 , 0.3, 0.4, 0.5],\n",
    "               'colsample_bytree' : [0.3, 0.4, 0.5, 0.7, 0.8]}\n",
    "\n",
    "randomCV = RandomizedSearchCV(estimator = XGBRegressor(),\n",
    "                              param_distributions = params_grid,\n",
    "                              scoring = make_scorer(r2_score),\n",
    "                              cv = StratifiedKFold(n_splits = 5),\n",
    "                              n_iter = 5)\n",
    "\n",
    "randomCV.fit(df_dummies, df_train_y_regresion)"
   ],
   "metadata": {
    "id": "7RTpJeq92DpS",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c628a9ba-c22a-41d7-fe70-c2cac713f798"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "randomCV.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediccion_y_metricas_regresion(randomCV.best_estimator_,df_test_dummies, df_test_y_regresion)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Observamos que, si bien las m√©tricas mejoraron, las diferencias al optimizar los par√°metros no fueron muy significativas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importancia de features\n",
    "Graficamos los 15 features m√°s importantes para el modelo con los hiperpar√°metros optimizados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_idx = randomCV.best_estimator_.feature_importances_.argsort()\n",
    "sorted_idx = sorted_idx[-15:]\n",
    "plt.barh(df_test_dummies.columns[sorted_idx], randomCV.best_estimator_.feature_importances_[sorted_idx])\n",
    "plt.xlabel(\"Xgboost Feature Importance\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Podemos ver que la ubicaci√≥n en Puerto Madero tiene a√∫n m√°s peso que en el modelo anterior y tambi√©n como algunos de los features con los que expandimos el dataset (calefaccion_radiante y cochera_fija) toman m√°s protagonismo, al igual que la superficie total."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exportaci√≥n del Modelo\n",
    "Finalmente exportamos el modelo utilizado para predecir, resultante de la optimizaci√≥n de hiperpar√°metros:"
   ],
   "metadata": {
    "id": "_f0JxWEL8GUY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/MODELOS/XGB_Regressor.json'\n",
    "else:\n",
    "  path = './MODELOS/XGB_Regressor.json'\n",
    "\n",
    "randomCV.best_estimator_.save_model(path)"
   ],
   "metadata": {
    "id": "RNVI92fe8WEP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9e1b9542-5eec-4f40-edbc-ebf7c8cecc42"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Redes Neuronales"
   ],
   "metadata": {
    "collapsed": false,
    "id": "HWpWT3GZ_TQT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.a Regresi√≥n"
   ],
   "metadata": {
    "id": "2HjJDe4W_iY-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.1 Preparaci√≥n del dataset"
   ],
   "metadata": {
    "id": "5xI2H0xyYm_B"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "x_train_regresion = df_train_x.drop([\"id\"], axis=1).copy()\n",
    "y_train_regresion = df_train_y_regresion.copy()\n",
    "x_test_regresion = df_test_x.drop([\"id\"], axis=1).copy()\n",
    "y_test_regresion = df_test_y_regresion.copy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizamos las entradas con StandardScaler:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "PKPRQVFS_TQT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "estandarizar(x_train_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])\n",
    "estandarizar(x_test_regresion, ['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total'])"
   ],
   "metadata": {
    "id": "s3xTEOkRlufG"
   },
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.2 B√∫squeda del mejor modelo"
   ],
   "metadata": {
    "id": "NjqmQr4pYrEE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creo una funci√≥n que me permite generar un modelo a partir de sus hiperpar√°metros. Esta funci√≥n tiene como par√°metros la cantidad de nodos de la primera y ante√∫ltima capa, la cantidad de capas ocultas, la funci√≥n de activaci√≥n y el optimizador. Todos los modelos que genera a excepci√≥n de los casos sin capas ocultas) tienen forma de 'pir√°mide'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "cantidad_de_columnas = x_train_regresion.shape[1]\n",
    "\n",
    "def crear_modelo(hidden_layers, first_layer_nodes, last_layer_nodes, activation_func, optimizer):\n",
    "\n",
    "    sequential = Sequential()\n",
    "    sequential.add(keras.layers.Dense(cantidad_de_columnas, input_shape=(cantidad_de_columnas,), activation=activation_func))\n",
    "\n",
    "    if hidden_layers is 0 or hidden_layers is 1:\n",
    "        decremento = 0\n",
    "    else:\n",
    "        decremento = math.ceil((first_layer_nodes - last_layer_nodes) / (hidden_layers - 1))\n",
    "\n",
    "    for i in range (0, hidden_layers):\n",
    "        nodos = first_layer_nodes - decremento * i\n",
    "        sequential.add(Dense(nodos, activation=activation_func))\n",
    "\n",
    "    sequential.add(Dense(1, activation=activation_func))\n",
    "\n",
    "    sequential.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mse', 'mean_absolute_percentage_error']\n",
    "    )\n",
    "\n",
    "    return sequential\n",
    "\n",
    "\n",
    "modelo =  KerasRegressor(build_fn=crear_modelo, verbose = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego busco el mejor modelo a partir de una grilla de par√°metros arbitrarios con el m√©todo de 'GridSearchCV'. El criterio de mejor modelo es el que tenga menor error cuadrado, o lo que es equivalente, mayor error cuadrado negado. Nos limitamos en la cantidad de folds en el CV por el consumo temporal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    hidden_layers=[0, 1],\n",
    "    first_layer_nodes = [math.ceil(cantidad_de_columnas * 0.7), math.ceil(cantidad_de_columnas * 0.5)],\n",
    "    last_layer_nodes = [5, cantidad_de_columnas * 0.5],\n",
    "    activation_func = ['sigmoid', 'relu', 'tanh'],\n",
    "    batch_size = [100],\n",
    "    epochs = [30],\n",
    "    optimizer=['RMSprop', 'adam'],\n",
    ")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = modelo,\n",
    "    param_grid = param_grid,\n",
    "    cv=5,\n",
    "    error_score='raise',\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=3,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos todos los modelos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-26 00:19:37.683654: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:37.732506: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:37.740021: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:37.745570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:39.308206: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:39.320550: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:39.407848: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:39.457748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:39.525168: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32788800 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:39.544281: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:39.579306: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:39.646399: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:54.349403: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:54.841631: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:54.908857: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:55.094087: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:55.796258: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:56.098335: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:56.186765: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:56.245879: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32788800 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:56.344263: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:19:56.391609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:19:56.552448: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:11.133218: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:11.464182: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:12.070792: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:12.178735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:12.521473: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:12.688488: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:12.810426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:12.971400: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:13.556160: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:13.557259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-26 00:20:13.855608: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32788800 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:13.987930: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:28.956637: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:29.162479: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n",
      "2022-12-26 00:20:29.281997: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 32789352 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(x_train_regresion, y_train_regresion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los par√°metros y m√©tricas del mejor modelo fueron:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"El error absoluto porcentual promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[2].result().numpy())\n",
    "print(\"El error absoluto cuadrado promedio del mejor modelo fue de: \", grid_result.best_estimator_.model.metrics[1].result().numpy())\n",
    "print(\"Los par√°metros √≥ptimizados fueron: \", grid.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.3 Predicci√≥n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_predict = grid.best_estimator_.model.evaluate(x_test_regresion, y_test_regresion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.4 M√©tricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"El error absoluto porcentual promedio fue de: \", grid_predict[2])\n",
    "print(\"El error absoluto cuadrado promedio (mse) fue de: \", grid_predict[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos c√≥mo se comporta la funci√≥n de p√©rdida del mejor modelo seg√∫n la cantidad de √©pocas utilizadas:"
   ],
   "metadata": {
    "id": "vmBg6ev_ZO-e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# epochs = range(60)\n",
    "# historia = grid_result.best_estimator_.model.history.history\n",
    "# historia\n",
    "# plt.plot(epochs, historia['mean_absolute_percentage_error'], color='orange', label='MSE')\n",
    "# plt.xlabel(\"epochs\")\n",
    "# plt.ylabel(\"MSE\")\n",
    "# plt.title('Error cuadr√°tico medio por cantidad de √©pocas')\n",
    "# plt.legend()\n",
    "# print(grid_result.best_estimator_.model.metrics[0].result().numpy(), grid_result.best_estimator_.model.metrics[0].name)\n",
    "max(grid_result.cv_results_[\"mean_test_score\"])\n",
    "grid_result.best_estimator_.model.history.params"
   ],
   "metadata": {
    "id": "BzNqiJex_TQU",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "outputId": "214e1825-e3d1-4d66-f0db-9b0cdf7a2550",
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = grid.predict(x_test_regresion)\n",
    "\n",
    "mse = metrics.mean_squared_error(\n",
    "    y_true  = y_test_regresion,\n",
    "    y_pred  = y_pred,\n",
    "    squared = True\n",
    ")\n",
    "\n",
    "print(f\"El error seg√∫n la m√©trica 'Mean Square Error' de test es: {mse}\")\n",
    "\n",
    "rmse = metrics.mean_squared_error(\n",
    "    y_true  = y_test_regresion,\n",
    "    y_pred  = y_pred,\n",
    "    squared = False\n",
    ")\n",
    "\n",
    "print(f\"El error seg√∫n la m√©trica 'Root Mean Square Error' de test es: {rmse}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.5 Exportaci√≥n de Datos"
   ],
   "metadata": {
    "id": "BeRZVagKeKzO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "id": "lO3v9OUzeKzP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/MODELOS/Redes_Regressor.json'\n",
    "else:\n",
    "  path = './MODELOS/Redes_Regressor.json'\n",
    "\n",
    "grid.best_estimator_.save_model(path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ac67727c-79b0-4c22-bb79-7bd9362015f4",
    "id": "tSuqGenveKzP",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.b Clasificaci√≥n\n",
    "___"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dXdWW-m9_TQV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.1 Preparaci√≥n del dataset"
   ],
   "metadata": {
    "id": "b176QcPLZj9N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_clasificacion = df_train_x.drop([\"id\"], axis=1).copy()\n",
    "y_train_clasificacion = df_train_y_clasificacion.copy()\n",
    "x_test_clasificacion = df_test_x.drop([\"id\"], axis=1).copy()\n",
    "y_test_clasificacion = df_test_y_clasificacion.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalizamos mediante Z-Score:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "JPjRt6tTOWIL"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_train_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)\n",
    "\n",
    "x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']] = zscore(x_test_clasificacion[['start_date', 'end_date', 'latitud', 'longitud', 'property_rooms', 'property_surface_total']], axis=1)"
   ],
   "metadata": {
    "id": "qDlv11yi8sR1",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicamos One Hot encoding a la columna target de entrenamiento y test, para que tenga 3 columnas al igual que la salida del modelo:"
   ],
   "metadata": {
    "collapsed": false,
    "id": "IZ2XeEKi_TQW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_train_clasificacion = pd.get_dummies(y_train_clasificacion, columns=['tipo_precio_3'], drop_first=False)\n",
    "y_test_clasificacion = pd.get_dummies(y_test_clasificacion, columns=['tipo_precio_3'], drop_first=False)"
   ],
   "metadata": {
    "id": "2jzMgy7b5js1",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.2 B√∫squeda del mejor modelo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funci√≥n auxiliar para que GridSearchCV realice el scoring de forma correcta."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def my_categorical_accuracy(y_true, y_pred) :\n",
    "    y_pred_df = pd.DataFrame(data=y_pred, columns=['alto', 'bajo', 'medio'])\n",
    "    res = round(accuracy_score(y_true, y_pred_df), 2)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos una funci√≥n que permite generar un modelo a partir de sus hiperpar√°metros configurables.\n",
    "Esta funci√≥n recibe como par√°metros la cantidad de capas ocultas extra, la cantidad de nodos de la √∫ltima capa oculta, la funci√≥n de activaci√≥n y metadata del clasificador."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def crear_modelo(extra_hidden_layers, last_layer_nodes, activation_func, optimizer, metricas, loss_func, meta):\n",
    "\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    X_shape_ = meta[\"X_shape_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "\n",
    "    sequential = Sequential()\n",
    "    sequential.add(keras.layers.Dense(n_features_in_ * 0.7, input_shape=X_shape_[1:], activation=activation_func))\n",
    "\n",
    "    if last_layer_nodes > n_features_in_:\n",
    "        decremento = 0\n",
    "    elif extra_hidden_layers is 0 or extra_hidden_layers is 1:\n",
    "        decremento = 0\n",
    "    else:\n",
    "        decremento = math.ceil((n_features_in_ - last_layer_nodes) / (extra_hidden_layers - 1))\n",
    "\n",
    "    for i in range (0, extra_hidden_layers):\n",
    "        nodos = n_features_in_ - decremento * i\n",
    "        sequential.add(Dense(nodos, activation=activation_func))\n",
    "\n",
    "    sequential.add(Dense(n_classes_, activation='softmax'))\n",
    "\n",
    "    return sequential\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos un modelo base, necesario seg√∫n la documentaci√≥n de SciKeras - KerasClassifier.\n",
    "Este modelo base ser√° editado por GridSearchCV al buscar los hiperpar√°metros."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_model = KerasClassifier(crear_modelo,\n",
    "                             loss=\"categorical_crossentropy\",\n",
    "                             extra_hidden_layers=1,\n",
    "                             last_layer_nodes=1,\n",
    "                             activation_func='sigmoid',\n",
    "                             )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Definimos los hiperpar√°metros posibles. Adem√°s de los necesarios por la funci√≥n crear_modelo, agregamos diferentes optimizadores, learning rates y cantidad de √©pocas."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = dict(\n",
    "    extra_hidden_layers=[0, 1],\n",
    "    last_layer_nodes = [10, 20],\n",
    "    activation_func = ['relu', 'softmax'],\n",
    "    batch_size = [100],\n",
    "    epochs = [5, 20],\n",
    "    optimizer__learning_rate = [0.001, 0.0001],\n",
    "    optimizer = [\"adam\", \"sge\"],\n",
    "    loss_func = [\"categorical_crossentropy\"],\n",
    ")\n",
    "\n",
    "gs = GridSearchCV(base_model,\n",
    "                  param_grid = param_grid,\n",
    "                  cv=5,\n",
    "                  scoring=make_scorer(my_categorical_accuracy),\n",
    "                  verbose=0,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos los diferentes modelos y obtenemos los mejores par√°metros."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gs.fit(x_train_clasificacion, y_train_clasificacion)\n",
    "print(\"Los par√°metros √≥ptimizados fueron: \", gs.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predecimos con el dataset de test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pr = gs.predict(x_test_clasificacion)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.b.4 M√©tricas\n",
    "Transformamos el array devuelto por el modelo a un dataframe de iguales columnas que y_test_clasificacion"
   ],
   "metadata": {
    "id": "W-KMjjHwaFjg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pr_df = pd.DataFrame(data=y_pr, columns=['alto', 'bajo', 'medio'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculamos las m√©tricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metricas_clasificacion(y_test_clasificacion, y_pr_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.a.5 Exportaci√≥n de Datos"
   ],
   "metadata": {
    "id": "5SsWSPw1fJYm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "id": "IlgF2MmmfJYn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/MODELOS/Redes_Classifier.json'\n",
    "else:\n",
    "  path = './MODELOS/Redes_Classifier.json'\n",
    "\n",
    "gs.best_estimator_.save_model(path)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "48479ec0-085c-4964-aa1d-b771dc5643e4",
    "id": "yjKFj8TjfJYn",
    "pycharm": {
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDpREdwKxB6m"
   },
   "source": [
    "## 3. Ensamble de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvLq10beDadg"
   },
   "source": [
    "### 3.1 Ensamble H√≠brido: Voting - Clasificaci√≥n\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAT6HU3buhLU"
   },
   "source": [
    "#### 3.1.1 Preparaci√≥n del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZNjL2W-vZvC"
   },
   "source": [
    "Para la parte de ensambles, lo que haremos ser√° utilizar nuevamente el dataset al cual se le aplic√≥ una reducci√≥n de su dimensionalidad en el trabajo pr√°ctico n¬∞1. \n",
    "\n",
    "Para esto lo que haremos ser√° trabajar con una copia del dataset modificado al inicio del trabajo, el cual usa como base el reducido mencionado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDp1eW_cHfxt"
   },
   "source": [
    "Para nuestra variable `target`, utilizaremos como convenci√≥n la misma que fue planteada para el tp1. √âsta consiste en subdividir a la variable pxm2 (precio por metro cuadrado) en 3 intervalos, 25% a bajo, 50% a medio y el otro 25% restante a alto. A su vez, se har√° la separaci√≥n tambien por tipo de propiedad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7T0ZW9l-dcqI",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "x_train_voting = x_train_clasificacion\n",
    "y_train_voting = y_train_clasificacion\n",
    "\n",
    "x_test_voting = x_test_clasificacion\n",
    "y_test_voting = y_test_clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "A modo de finalizaci√≥n de este trabajo, haremos un peque√±o repaso sobre todos los puntos que analizamos y sus respectivos resultados y/o observaciones hechos por nosotros:\n",
    "\n",
    "Sobre el an√°lisis realizado en el apartado de **procesamiento del lenguaje natural**, y en particular haciendo referencia a las m√©tricas que obtuvimos luego del entrenamiento y predicci√≥n con el dataset producto de la ampliaci√≥n, utilizando el modelo XGBoost, pudimos observar que si bien a√∫n las m√©tricas no nos resultan del todo satisfactorias cumplen con el objetivo de mejorar las resultantes del trabajo anterior. M√°s all√° de que la cantidad de aciertos contin√∫a sin incrementar, tanto el error MSE como el RMSE decrecieron ofreciendo mejores resultados. Por otro lado, el coeficiente de determinaci√≥n se increment√≥ notoriamente llegando casi a un 0.9%. \n",
    "\n",
    "En cuanto a lo referido sobre **redes neuronales**, la comparaci√≥n ser√° directamente en base a los nuevos modelos ya que el dataset utilizado es compartido en ambos trabajos. Dicho esto, el error cometido en el modelo de regresi√≥n es significativamente peque√±o. Teniendo en cuenta los resultantes del TP1, si utilizamos el menor luego de que √©stos tuvieron su optimizaci√≥n de par√°metros correspondiente, notamos que el que mejor performa es XGBoost con un MSE de 51650994876 (al cual de todas formas le atribu√≠mos arrastre de error en nuestro planteo). Utilizando redes neuronales cometemos tan solo un error cuadr√°tico medio equivalente a 1.36. Por otro lado, en lo que respecta al modelo de clasificaci√≥n, obtuvimos resultados bastante similares. Si bien tanto el accuracy, precisi√≥n y F1-Score dieron distintos, la diferencia es de tan solo uno/dos puntos. Con esto concluimos que para clasificaci√≥n no se notan mejoras por sobre los modelos utilizados en el trabajo anterior.\n",
    "\n",
    "Como √∫ltimo requerimiento se pidi√≥ estudiar las m√©tricas tanto para regresi√≥n como clasificaci√≥n pero haciendo uso de **ensambles**, en particular de tipo h√≠bridos. En lo que respecta al utilizado para clasificaci√≥n (Voting) obtuvimos mejores resultados para las m√©tricas de Accuracy, Recall y F1-Score. Sin embargo, aunque en Precisi√≥n disminuy√≥ un poco, esta diferencia contin√∫a siendo no significativa. Pasando al ensamble de regresi√≥n (Stacking) el MSE resultante que obtuvimos fue 238481755830. Creemos que nuevamente estamos cometiendo involuntariamente alg√∫n arrastre de error en alguno de los incisos desarrollados, ya que este error es incluso mayor a los cometidos en los modelos individuales desarrollados en el TP1, y no estar√≠a respetando la regla principal de ‚Äò*La sabidur√≠a de las multitudes*‚Äô."
   ],
   "metadata": {
    "id": "CE40zH4PI4xY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bajo = y_train_voting['bajo'].sum() + y_test_voting[y_test_voting == 'bajo'].count()\n",
    "medio = y_train_voting['medio'].sum() + y_test_voting[y_test_voting == 'medio'].count()\n",
    "alto = y_train_voting['alto'].sum() + y_test_voting[y_test_voting == 'alto'].count()\n",
    "\n",
    "print(f\"Se observaron: \\n - {round(bajo,3)} registros de tipo 'bajo'. \\n - {round(medio,3)} registros de tipo 'medio'. \\n - {round(alto,3)} registros de tipo 'alto'.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.2 Definici√≥n del Ensamble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para el tipo de ensamble **voting**, lo que necesitaremos ser√° contar con `n` cantidad de modelos previamente entrenados para luego someterlos a una votaci√≥n. De la misma, saldr√° la clasificaci√≥n para la nueva instancia en base a lo que indique la mayor√≠a de ellos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Elegimos tomar como modelos los mismos empleados en el TP1:\n",
    "\n",
    "\n",
    "*   √Årbol de Decisi√≥n\n",
    "*   Random Forest\n",
    "*   KNN\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dcs_clf = DecisionTreeClassifier()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "knn_clf = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Una vez que contamos con los modelos que vamos a utilizar en el ensamble, procedemos a su creaci√≥n. En este caso particular decidimos utilizar el tipo de votaci√≥n hard el cual utilizar√° la regla de la mayor√≠a. Por otro lado, utilizamos el hiperpar√°metro `estimators` para definir como nos vamos a referir a dichos modelos."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vot_clf = VotingClassifier(estimators = [('dcs', dcs_clf), ('rnd', rnd_clf), ('knn', knn_clf)], voting = 'hard')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.3 Entrenamiento y Predicci√≥n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reorganizamos los valores predichos para que queden en una sola columna, y comparamos con el conjunto de prueba:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_voting_arr = np.apply_along_axis(convert_b_m_a, axis=1, arr=y_train_voting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seguimos reacomodando los valores para poder calcular las m√©tricas correspondientes, notemos que no pueden guardarse valores equivalentes al string 'medio' en el array:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aplicamos estrategias de transformaci√≥n de datos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_voting_arr = np.where(y_train_voting_arr == 'medi', 'medio', y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.unique(y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, entrenamos el ensamle:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vot_clf.fit(x_train_voting, y_train_voting_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_voting = vot_clf.predict(x_test_voting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.4 M√©tricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder determinar que tan bueno resulto el modelo, lo que haremos ser√° observar las `m√©tricas` resultantes de una predicci√≥n con los datos de test. Recordemos que nuestras funcinoes de metricas fueron definidas al inicio de este trabajo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metricas_clasificacion(y_test_voting, y_pred_voting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A su vez, tambi√©n podemos visualizar los mismos a trav√©s de la siguiente matriz de confusi√≥n."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test_voting, y_pred_voting)\n",
    "sns.heatmap(matrix,cmap='GnBu',annot=True,fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.4 Exportaci√≥n de Datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/MODELOS/Voting_Classifier.joblib'\n",
    "else:\n",
    "  path = './MODELOS/Voting_Classifier.joblib'\n",
    "\n",
    "dump(vot_clf, path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Ensamble H√≠brido: Stacking - Regresi√≥n\n",
    "___"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1.1 Preparaci√≥n del dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nuevamente, utilizamos los datasets de train y test previamente separados:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_stacking = x_train_regresion\n",
    "y_train_stacking = y_train_regresion\n",
    "\n",
    "x_test_stacking = x_test_regresion\n",
    "y_test_stacking = y_test_regresion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.2 Definici√≥n del Ensamble\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lo que haremos en esta nueva secci√≥n, ser√° implementar un nuevo tipo de ensable h√≠brido con la salvedad de que esta vez utilizaremos el tipo `cascading`.\n",
    "El mismo se basa en el entrenamiento de distintos `modelos base`, y a su vez utilizar√° un `meta-modelo` el cual realizar√° su predicci√≥n en base a las predicciones de los diferentes modelos comentados anteriormente.\n",
    "\n",
    "Como es indicado por el enunciado del trabajo se utilizar√°n modelos de regresi√≥n. En particular, decidimos trabajar con:\n",
    "\n",
    "\n",
    "*   KNN\n",
    "*   XGBoost\n",
    "*   AdaBoost\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_rgs = KNeighborsRegressor()\n",
    "xgb_rgs = XGBRegressor()\n",
    "adb_rgs = AdaBoostRegressor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Luego utilizamos los mismos para definir nuestro modelo base, en el cual luego se basar√° el meta-modelo."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_models = [('KNN', knn_rgs),\n",
    "               ('XGBoost', xgb_rgs),\n",
    "               ('AdaBoost', adb_rgs)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como mencionamos, a continuaci√≥n los utilizaremos para definir nuestro meta-modelo. Para este √∫ltimo, decidimos emplear el modelo de regresi√≥n logistica."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "meta_model = GradientBoostingRegressor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creamos nuestro ensamble indicando como modelos estimadores Knn, XGBoost y AdaBoost, y como estimador final el modelo de Regresi√≥n Lineal."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s = 5\n",
    "n = 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacking_model = StackingRegressor(estimators=base_models,\n",
    "                                    final_estimator=meta_model,\n",
    "                                    passthrough=True,\n",
    "                                    cv=s,\n",
    "                                    verbose=n)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.3 Entrenamiento y Predicci√≥n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_scores = defaultdict()\n",
    "\n",
    "for name, model in base_models:\n",
    "    print('Evaluating {}'.format(name))\n",
    "    scores = evaluate_model(model, x_train_stacking, y_train_stacking, s, n)\n",
    "    model_scores[name] = scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos c√≥mo resultaron los scores de los modelos:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_results(model_scores, name='stacking_model_cv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Entrenamos el modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stacking_model.fit(x_train_stacking, y_train_stacking)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente haremos la predicci√≥n:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_stacking = stacking_model.predict(x_test_stacking)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 M√©tricas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para poder evaluar la performance que obtuvo nuestro modelo utilizaremos la m√©trica de evaluaci√≥n del error cuadr√°tico medio (MSE) como se pide por enunciado."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse = metrics.mean_squared_error(\n",
    "        y_true  = y_test_stacking,\n",
    "        y_pred  = y_pred_stacking,\n",
    "        squared = True\n",
    "       )\n",
    "\n",
    "print(f\"El error seg√∫n la m√©trica 'Mean Square Error' de test es: {mse}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2.4 Exportaci√≥n de Datos"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finalmente, exportamos el modelo utilizado:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  path = '/content/drive/MyDrive/üìî OrganizacioÃÅn de Datos (75.06)/TPS/TP2/MODELOS/Stacking_Regressor.joblib'\n",
    "else:\n",
    "  path = './MODELOS/Stacking_Regressor.joblib'\n",
    "\n",
    "dump(stacking_model, path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusiones"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "EAT6HU3buhLU",
    "_kG7ZRlKuaxT",
    "D8sgMCouvLx-"
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
